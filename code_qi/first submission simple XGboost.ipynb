{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# La Compagnie du Vent Challenge \n",
    "1.first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pacakge import\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df_parc_data(folder_adr,list_num_parc,list_date_parc):\n",
    "    \"\"\"\n",
    "    a function to load (and concatene) informations from Parc_XX.csv\n",
    "    \"\"\"\n",
    "    df_parc_data = pd.DataFrame()\n",
    "    for num_parc in list_num_parc:\n",
    "        for date_parc in list_date_parc:\n",
    "            df_parc_data = df_parc_data.append(pd.read_csv(folder_adr+\"//Parc%s_%s.csv\"%(num_parc,date_parc),sep=\";\",decimal=','),ignore_index=True)\n",
    "    df_parc_data[\"Date\"] = pd.to_datetime(df_parc_data[\"Date\"],format = \"%d/%m/%Y %H:%M\")\n",
    "    return df_parc_data\n",
    "\n",
    "def load_parc_data(folder_adr,list_num_parc,list_date_parc,list_col_parc_data_to_keep):\n",
    "    \"\"\"\n",
    "    keep only fonctionnement == 1 and selection columns\n",
    "    \"\"\"\n",
    "    df_parc_data = create_df_parc_data(folder_adr,list_num_parc,list_date_parc)\n",
    "    # keep only fonctionnment = 1\n",
    "    df_parc_data =  df_parc_data[df_parc_data[\"Fonctionnement\"]==1]\n",
    "    print(df_parc_data.shape)\n",
    "    return df_parc_data[list_col_parc_data_to_keep]\n",
    "\n",
    "def add_feature_timestamp(df_parc_data):\n",
    "    \"\"\"\n",
    "    create time features\n",
    "    \"\"\"\n",
    "    df_parc_data[\"Month\"] = df_parc_data[\"Date\"].dt.month\n",
    "    df_parc_data[\"Day\"] = df_parc_data[\"Date\"].dt.day\n",
    "    df_parc_data[\"Hour\"] = df_parc_data[\"Date\"].dt.hour\n",
    "    df_parc_data[\"Weekday\"] = df_parc_data[\"Date\"].dt.weekday\n",
    "    df_parc_data[\"Date_hour_int\"] = df_parc_data[\"Date\"].dt.year*10**6  + df_parc_data[\"Date\"].dt.month*10**4 +\\\n",
    "    df_parc_data[\"Date\"].dt.day*100 + df_parc_data[\"Date\"].dt.hour\n",
    "    df_parc_data[\"nb_hour\"] = df_parc_data[\"Date\"].apply(lambda x: np.floor((x- datetime.datetime(2015,1,1)).total_seconds()/3600))\n",
    "    return \n",
    " \n",
    "def add_feature_state(df_parc_data):\n",
    "    \"\"\"\n",
    "    create state features\n",
    "    \"\"\"\n",
    "    df_parc_data[\"State_pause\"] = 0  \n",
    "    df_parc_data.loc[df_parc_data[\"State\"]==2,\"State_pause\"]=1\n",
    "    df_parc_data[\"State_ambiant\"] = 0\n",
    "    df_parc_data.loc[df_parc_data[\"State\"]==999,\"State_ambiant\"]=1\n",
    "    df_parc_data[\"state_pause_ambiant\"] = df_parc_data[\"State_pause\"] + df_parc_data[\"State_ambiant\"]\n",
    "    return\n",
    "\n",
    "def min_to_hour(df_parc_data):\n",
    "    \"\"\"\n",
    "    convert minute dataframe to hourly dataframe\n",
    "    \"\"\"\n",
    "    df_parc_data_hour = df_parc_data.groupby([\"Date_hour_int\",\"Eolienne\"]).mean()\n",
    "    return df_parc_data_hour.reset_index()\n",
    "\n",
    "def get_eolienne_list(df_parc_data):\n",
    "    \"\"\"\n",
    "    get all eolienne name in the df\n",
    "    \"\"\"\n",
    "    return df_parc_data[\"Eolienne\"].drop_duplicates().tolist()\n",
    "\n",
    "def create_df_meteo_from_list_grille(folder_adr,list_grille):\n",
    "    \"\"\"\n",
    "    a function to load (and concatenate) informations from PrevMeteo_GrilleXX.xlsx\n",
    "    \"\"\"\n",
    "    df_meteo  = pd.DataFrame()\n",
    "    for grille_C in list_grille:\n",
    "        df_meteo_tmp =  pd.read_excel(folder_adr +'/PrevMeteo_Grille%s.xlsx'%(grille_C),sep=';')\n",
    "        df_meteo_tmp[\"grille\"] = grille_C\n",
    "        df_meteo = df_meteo.append(df_meteo_tmp,ignore_index=True)\n",
    "    df_meteo[\"date\"] = pd.to_datetime(df_meteo[\"date\"],format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    df_meteo.rename(columns= {\"date\":\"Date\"},inplace=True)\n",
    "    return df_meteo\n",
    "\n",
    "def meteo_grill_merge(df_meteo,feature_list,join_key):\n",
    "    \"\"\"\n",
    "    merge meteo data by grille\n",
    "    \"\"\"\n",
    "    grille_list = df_meteo[\"grille\"].drop_duplicates().tolist() \n",
    "    all_feature_list = feature_list + join_key\n",
    "    grille_name = grille_list[0]\n",
    "    index = df_meteo[\"grille\"] == grille_name\n",
    "    df_meteo_merged = df_meteo.loc[index,all_feature_list]\n",
    "    df_meteo_merged.columns =  [x +\"_\"+ str(grille_name) for x in feature_list] + join_key\n",
    "    if len(grille_list)==1:\n",
    "        return df_meteo_merged\n",
    "    for grille_name in grille_list[1:]:\n",
    "        index = df_meteo[\"grille\"] == grille_name\n",
    "        df_meteo_merged_p = df_meteo.loc[index,all_feature_list]\n",
    "        df_meteo_merged_p.columns =  [x +\"_\"+ str(grille_name) for x in feature_list] + join_key\n",
    "        df_meteo_merged =  pd.merge(df_meteo_merged,df_meteo_merged_p,on=\"Date_hour_int\",how=\"left\")\n",
    "    return df_meteo_merged\n",
    "\n",
    "# define new objective fonction for xgboost\n",
    "def fair_obj(preds, dtrain):\n",
    "    \"\"\"\n",
    "    fair_obj function to optimize approximatively MAE\n",
    "    \"\"\"\n",
    "    fair_constant = 30\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def mean_absolute_err(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    MAE Metric\n",
    "    \"\"\"\n",
    "    y_true = y_true\n",
    "    y_pred= y_pred.get_label()\n",
    "    return \"MAE\",np.mean(np.abs((y_true - y_pred))) \n",
    "\n",
    "def time_zone(df_meteo):\n",
    "    \"\"\"\n",
    "    Aline the 2 time zone in the meteo file and production file\n",
    "    \"\"\"\n",
    "    df_meteo[\"Date\"] = df_meteo[\"Date\"] + timedelta(hours=1)\n",
    "    df_meteo_new = df_meteo[(df_meteo[\"fc_hor\"]>=23)&(df_meteo[\"fc_hor\"]<=46)]\n",
    "    del(df_meteo)\n",
    "    gc.collect()\n",
    "    return df_meteo_new\n",
    "\n",
    "def meteo_delta_feature(df_meteo):\n",
    "    \"\"\"\n",
    "    generate meteo delta feature\n",
    "    \"\"\"\n",
    "    df_meteo[\"vit_100_delta\"] =df_meteo[\"vit_100\"] - df_meteo[\"vit_100\"].shift(1)\n",
    "    df_meteo[\"vit_10_delta\"] =df_meteo[\"vit_10\"] - df_meteo[\"vit_10\"].shift(1)\n",
    "    df_meteo[\"dir_100_delta\"] =df_meteo[\"dir_100\"] - df_meteo[\"dir_100\"].shift(1)\n",
    "    df_meteo[\"dir_10_delta\"] =df_meteo[\"dir_10\"] - df_meteo[\"dir_10\"].shift(1)\n",
    "    return \n",
    "\n",
    "def submission_generation(res,save_adr):\n",
    "    \"\"\"\n",
    "    generate submission file\n",
    "    \"\"\"\n",
    "    submission = pd.read_csv(\"..//data//submit_benchmark.csv\",sep=\";\")\n",
    "    submission[\"Date\"] = pd.to_datetime(submission[\"Date\"],format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    add_feature_timestamp(submission)\n",
    "    submission =  submission[[\"Date_hour_int\",\"Eolienne\",\"Date\"]]\n",
    "    submission=pd.merge(submission,res,on=[\"Date_hour_int\",\"Eolienne\"],how=\"left\")[[\"Date\",\"Eolienne\",\"pred\"]]\n",
    "    submission.to_csv(save_adr,sep=';',header=True,index = False)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12910771, 17)\n"
     ]
    }
   ],
   "source": [
    "# parc data \n",
    "folder_adr = \"..//data\"\n",
    "list_num_parc = [1,2,3]\n",
    "list_date_parc = [\"2015\",\"2016\",\"2017\"]\n",
    "list_col_parc_data_to_keep = [\"Date\",\"Eolienne\",\"Production\",\"Fonctionnement\",\"CatÃ©gorie\",\"State\",\"Etat\",\"Vent\"]\n",
    "parc_data_min = load_parc_data(folder_adr,list_num_parc,list_date_parc,list_col_parc_data_to_keep)\n",
    "\n",
    "#forecast data\n",
    "list_grille= [6,7,8,10,11,12]\n",
    "##for this example notebook, we will only take one \"grille\" (=9) \n",
    "df_meteo = create_df_meteo_from_list_grille(folder_adr,list_grille)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add feature and convert to hourly data\n",
    "add_feature_timestamp(parc_data_min)\n",
    "add_feature_state(parc_data_min)\n",
    "parc_data_hour =  min_to_hour(parc_data_min)\n",
    "df_meteo = time_zone(df_meteo)\n",
    "meteo_delta_feature(df_meteo)\n",
    "add_feature_timestamp(df_meteo)\n",
    "\n",
    "# we don't need the minute data any more\n",
    "del(parc_data_min)\n",
    "gc.collect()\n",
    "\n",
    "eolienne_list = get_eolienne_list(parc_data_hour)\n",
    "feature_list = [\"vit_100\",\"vit_10\",'dir_100','dir_10',\"vit_100_delta\",\"vit_10_delta\",'dir_100_delta','dir_10_delta',\"fc_hor\"]\n",
    "join_key = [\"Date_hour_int\"]\n",
    "meteo_grill_merged = meteo_grill_merge(df_meteo,feature_list,join_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parc_data_hour = pd.merge(parc_data_hour,meteo_grill_merged,on=[\"Date_hour_int\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test validation split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189225, 68)\n",
      "(26884, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "date_split_test = 2017010100\n",
    "parc_data_hour_train = parc_data_hour[parc_data_hour[\"Date_hour_int\"]<date_split_test]\n",
    "parc_data_hour_test = parc_data_hour[parc_data_hour[\"Date_hour_int\"]>=date_split_test]\n",
    "\n",
    "parc_data_hour_train.dropna(inplace=True)\n",
    "print(parc_data_hour_train.shape)\n",
    "print(parc_data_hour_test.shape)\n",
    "\n",
    "parc_data_hour_train.sort_values(\"Date_hour_int\",inplace=True)\n",
    "parc_data_hour_train_train = parc_data_hour_train.iloc[:94618,:]\n",
    "parc_data_hour_train_test  = parc_data_hour_train.iloc[94618:189236,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature use in model \n",
    "list_col_model = [\"vit_100_11\",\"vit_10_11\",'dir_100_11','dir_10_11',\"vit_100_delta_11\",\"vit_10_delta_11\",'dir_100_delta_11','dir_10_delta_11',\n",
    "                  \"vit_100_10\",\"vit_10_10\",'dir_100_10','dir_10_10',\"vit_100_delta_10\",\"vit_10_delta_10\",'dir_100_delta_10','dir_10_delta_10',\n",
    "                  \"vit_100_12\",\"vit_10_12\",'dir_100_12','dir_10_12',\"vit_100_delta_12\",\"vit_10_delta_12\",'dir_100_delta_12','dir_10_delta_12',\n",
    "                  \"vit_100_8\",\"vit_10_8\",'dir_100_8','dir_10_8',\"vit_100_delta_8\",\"vit_10_delta_8\",'dir_100_delta_8','dir_10_delta_8',\n",
    "                  \"vit_100_7\",\"vit_10_7\",'dir_100_7','dir_10_7',\"vit_100_delta_7\",\"vit_10_delta_7\",'dir_100_delta_7','dir_10_delta_7',\n",
    "                  \"vit_100_6\",\"vit_10_6\",'dir_100_6','dir_10_6',\"vit_100_delta_6\",\"vit_10_delta_6\",'dir_100_delta_6','dir_10_delta_6'\n",
    "                 ]\n",
    "col_target =\"Production\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.02,  'subsample': 0.99, 'colsample_bytree': 0.95, \n",
    "              'objective': 'reg:linear', 'max_depth':20, 'min_child_weight':20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae optimiser \n",
      "[0]\teval-rmse:660.722\ttrain-rmse:739.176\teval-MAE:441.427\ttrain-MAE:512.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\teval-rmse:311.277\ttrain-rmse:338.502\teval-MAE:208.608\ttrain-MAE:224.607\n",
      "[100]\teval-rmse:281.471\ttrain-rmse:295.967\teval-MAE:189.51\ttrain-MAE:192.869\n",
      "[150]\teval-rmse:277.404\ttrain-rmse:285.155\teval-MAE:187.194\ttrain-MAE:183.477\n",
      "[200]\teval-rmse:276.055\ttrain-rmse:279.527\teval-MAE:186.513\ttrain-MAE:178.443\n",
      "[250]\teval-rmse:275.556\ttrain-rmse:275.53\teval-MAE:186.023\ttrain-MAE:174.625\n",
      "[299]\teval-rmse:275.314\ttrain-rmse:271.477\teval-MAE:185.759\ttrain-MAE:170.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5088: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae optimiser \n",
      "[0]\teval-rmse:654.239\ttrain-rmse:713.269\teval-MAE:424.028\ttrain-MAE:488.541\n",
      "[50]\teval-rmse:366.017\ttrain-rmse:381.788\teval-MAE:232.549\ttrain-MAE:246.823\n",
      "[100]\teval-rmse:338.308\ttrain-rmse:342.637\teval-MAE:215.587\ttrain-MAE:217.946\n",
      "[150]\teval-rmse:335.092\ttrain-rmse:333.78\teval-MAE:212.731\ttrain-MAE:208.99\n",
      "[200]\teval-rmse:334.828\ttrain-rmse:330.316\teval-MAE:212.361\ttrain-MAE:204.499\n",
      "[250]\teval-rmse:334.6\ttrain-rmse:327.539\teval-MAE:212.256\ttrain-MAE:200.809\n",
      "[299]\teval-rmse:334.293\ttrain-rmse:324.854\teval-MAE:212.32\ttrain-MAE:197.92\n",
      "mae optimiser \n",
      "[0]\teval-rmse:673.057\ttrain-rmse:730.027\teval-MAE:445.671\ttrain-MAE:508.096\n",
      "[50]\teval-rmse:377.412\ttrain-rmse:384.196\teval-MAE:239.995\ttrain-MAE:249.876\n",
      "[100]\teval-rmse:349.534\ttrain-rmse:344.207\teval-MAE:223.705\ttrain-MAE:219.559\n",
      "[150]\teval-rmse:345.73\ttrain-rmse:334.874\teval-MAE:221.391\ttrain-MAE:210.213\n",
      "[200]\teval-rmse:345.116\ttrain-rmse:330.57\teval-MAE:221.018\ttrain-MAE:205.144\n",
      "[250]\teval-rmse:344.557\ttrain-rmse:327.662\teval-MAE:220.466\ttrain-MAE:201.127\n",
      "[299]\teval-rmse:343.775\ttrain-rmse:324.702\teval-MAE:219.936\ttrain-MAE:197.546\n",
      "mae optimiser \n",
      "[0]\teval-rmse:648.349\ttrain-rmse:726\teval-MAE:429.263\ttrain-MAE:501.643\n",
      "[50]\teval-rmse:302.768\ttrain-rmse:334.811\teval-MAE:202.481\ttrain-MAE:220.001\n",
      "[100]\teval-rmse:274.76\ttrain-rmse:294.563\teval-MAE:184.388\ttrain-MAE:189.9\n",
      "[150]\teval-rmse:271.041\ttrain-rmse:284.28\teval-MAE:181.325\ttrain-MAE:180.794\n",
      "[200]\teval-rmse:269.982\ttrain-rmse:279.907\teval-MAE:180.449\ttrain-MAE:176.457\n",
      "[250]\teval-rmse:269.961\ttrain-rmse:276.643\teval-MAE:180.381\ttrain-MAE:173.152\n",
      "[299]\teval-rmse:269.97\ttrain-rmse:273.446\teval-MAE:180.468\ttrain-MAE:170.078\n",
      "mae optimiser \n",
      "[0]\teval-rmse:616.304\ttrain-rmse:694.41\teval-MAE:393.671\ttrain-MAE:465.823\n",
      "[50]\teval-rmse:296.814\ttrain-rmse:323.993\teval-MAE:193.862\ttrain-MAE:209.209\n",
      "[100]\teval-rmse:267.887\ttrain-rmse:282.221\teval-MAE:176.515\ttrain-MAE:180.768\n",
      "[150]\teval-rmse:263.748\ttrain-rmse:271.975\teval-MAE:173.212\ttrain-MAE:171.631\n",
      "[200]\teval-rmse:262.914\ttrain-rmse:267.178\teval-MAE:172.403\ttrain-MAE:167.296\n",
      "[250]\teval-rmse:262.83\ttrain-rmse:263.75\teval-MAE:172.283\ttrain-MAE:164.125\n",
      "[299]\teval-rmse:263.159\ttrain-rmse:260.561\teval-MAE:172.493\ttrain-MAE:161.295\n",
      "mae optimiser \n",
      "[0]\teval-rmse:601.564\ttrain-rmse:668.744\teval-MAE:380.921\ttrain-MAE:441.267\n",
      "[50]\teval-rmse:293.091\ttrain-rmse:321.374\teval-MAE:190.846\ttrain-MAE:204.269\n",
      "[100]\teval-rmse:263.961\ttrain-rmse:280.671\teval-MAE:174.138\ttrain-MAE:176.685\n",
      "[150]\teval-rmse:259.461\ttrain-rmse:269.812\teval-MAE:171.066\ttrain-MAE:167.56\n",
      "[200]\teval-rmse:258.841\ttrain-rmse:265.512\teval-MAE:170.444\ttrain-MAE:163.497\n",
      "[250]\teval-rmse:259.032\ttrain-rmse:262.538\teval-MAE:170.488\ttrain-MAE:160.572\n",
      "[299]\teval-rmse:259.016\ttrain-rmse:259.895\teval-MAE:170.569\ttrain-MAE:158.06\n",
      "mae optimiser \n",
      "[0]\teval-rmse:594.134\ttrain-rmse:664.289\teval-MAE:370.488\ttrain-MAE:434.657\n",
      "[50]\teval-rmse:289.747\ttrain-rmse:310.308\teval-MAE:186.445\ttrain-MAE:199.848\n",
      "[100]\teval-rmse:262.108\ttrain-rmse:267.373\teval-MAE:170.55\ttrain-MAE:170.643\n",
      "[150]\teval-rmse:259.006\ttrain-rmse:256.467\teval-MAE:168.438\ttrain-MAE:161.186\n",
      "[200]\teval-rmse:258.749\ttrain-rmse:250.81\teval-MAE:168.384\ttrain-MAE:156.318\n",
      "[250]\teval-rmse:259.073\ttrain-rmse:246.755\teval-MAE:168.651\ttrain-MAE:152.651\n",
      "[299]\teval-rmse:259.082\ttrain-rmse:244.031\teval-MAE:168.776\ttrain-MAE:150.268\n",
      "mae optimiser \n",
      "[0]\teval-rmse:573.627\ttrain-rmse:658.064\teval-MAE:354.416\ttrain-MAE:427.456\n",
      "[50]\teval-rmse:280.389\ttrain-rmse:302.271\teval-MAE:179.636\ttrain-MAE:194.42\n",
      "[100]\teval-rmse:255.448\ttrain-rmse:259.717\teval-MAE:165.682\ttrain-MAE:165.65\n",
      "[150]\teval-rmse:252.493\ttrain-rmse:248.749\teval-MAE:163.494\ttrain-MAE:156.465\n",
      "[200]\teval-rmse:252.117\ttrain-rmse:244.13\teval-MAE:163.111\ttrain-MAE:152.308\n",
      "[250]\teval-rmse:252.179\ttrain-rmse:240.974\teval-MAE:163.221\ttrain-MAE:149.484\n",
      "[299]\teval-rmse:252.096\ttrain-rmse:238.199\teval-MAE:163.283\ttrain-MAE:147.046\n",
      "mae optimiser \n",
      "[0]\teval-rmse:579.338\ttrain-rmse:652.564\teval-MAE:350.385\ttrain-MAE:418.201\n",
      "[50]\teval-rmse:277.716\ttrain-rmse:300.049\teval-MAE:175.692\ttrain-MAE:191.024\n",
      "[100]\teval-rmse:251.346\ttrain-rmse:257.989\teval-MAE:161.401\ttrain-MAE:163.425\n",
      "[150]\teval-rmse:248.613\ttrain-rmse:247.774\teval-MAE:159.473\ttrain-MAE:154.688\n",
      "[200]\teval-rmse:248.378\ttrain-rmse:243.243\teval-MAE:159.427\ttrain-MAE:150.551\n",
      "[250]\teval-rmse:248.445\ttrain-rmse:240.013\teval-MAE:159.59\ttrain-MAE:147.532\n",
      "[299]\teval-rmse:248.46\ttrain-rmse:237.24\teval-MAE:159.748\ttrain-MAE:145.196\n",
      "mae optimiser \n",
      "[0]\teval-rmse:583.333\ttrain-rmse:649.452\teval-MAE:364.46\ttrain-MAE:422.327\n",
      "[50]\teval-rmse:286.91\ttrain-rmse:300.749\teval-MAE:184.013\ttrain-MAE:192.563\n",
      "[100]\teval-rmse:260.818\ttrain-rmse:259.379\teval-MAE:169.275\ttrain-MAE:165.274\n",
      "[150]\teval-rmse:258.259\ttrain-rmse:249.477\teval-MAE:167.461\ttrain-MAE:156.62\n",
      "[200]\teval-rmse:257.635\ttrain-rmse:243.933\teval-MAE:167.007\ttrain-MAE:151.765\n",
      "[250]\teval-rmse:257.708\ttrain-rmse:240.795\teval-MAE:166.878\ttrain-MAE:148.878\n",
      "[299]\teval-rmse:257.936\ttrain-rmse:238.034\teval-MAE:166.977\ttrain-MAE:146.379\n",
      "mae optimiser \n",
      "[0]\teval-rmse:644.857\ttrain-rmse:725.903\teval-MAE:421.931\ttrain-MAE:502.073\n",
      "[50]\teval-rmse:353.827\ttrain-rmse:366.602\teval-MAE:228.518\ttrain-MAE:241.406\n",
      "[100]\teval-rmse:334.522\ttrain-rmse:330.021\teval-MAE:214.457\ttrain-MAE:212.499\n",
      "[150]\teval-rmse:333.427\ttrain-rmse:321.465\teval-MAE:212.844\ttrain-MAE:204.104\n",
      "[200]\teval-rmse:333.833\ttrain-rmse:318.354\teval-MAE:212.941\ttrain-MAE:200.007\n",
      "[250]\teval-rmse:334.114\ttrain-rmse:315.859\teval-MAE:213.159\ttrain-MAE:196.896\n",
      "[299]\teval-rmse:334.2\ttrain-rmse:312.843\teval-MAE:213.478\ttrain-MAE:193.749\n"
     ]
    }
   ],
   "source": [
    "parc_data_hour_train_test[\"xgb_site\"]=np.nan\n",
    "for eol_name in eolienne_list:\n",
    "    Eolienne_index = parc_data_hour_train_train[\"Eolienne\"]==eol_name\n",
    "    Eolienne_index_test = parc_data_hour_train_test[\"Eolienne\"]==eol_name\n",
    "    xgdtrain = xgb.DMatrix(parc_data_hour_train_train[Eolienne_index][list_col_model], parc_data_hour_train_train[Eolienne_index][col_target]) \n",
    "    xgdtest = xgb.DMatrix(parc_data_hour_train_test[Eolienne_index_test][list_col_model], parc_data_hour_train_test[Eolienne_index_test][col_target])\n",
    "    evallist  = [(xgdtest,'eval'), (xgdtrain,'train')]\n",
    "    print(\"mae optimiser \")\n",
    "    xgb_model = xgb.train(params = our_params ,dtrain = xgdtrain, evals=evallist, num_boost_round = 250,verbose_eval=50,obj=fair_obj,feval=mean_absolute_err)\n",
    "    #print(\"rmse optimiser\")\n",
    "    #xgb_model_2 = xgb.train(params = our_params ,dtrain = xgdmat, evals=evallist, num_boost_round = 250,verbose_eval=250,feval=mean_absolute_err)\n",
    "    parc_data_hour_train_test[\"xgb_site\"][Eolienne_index_test]=xgb_model.predict(xgdtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae optimiser \n",
      "[0]\teval-rmse:557.861\ttrain-rmse:622.014\teval-MAE:362.725\ttrain-MAE:423.529\n",
      "[10]\teval-rmse:392.018\ttrain-rmse:422.162\teval-MAE:254.072\ttrain-MAE:278.433\n",
      "[20]\teval-rmse:345.21\ttrain-rmse:358.369\teval-MAE:222.067\ttrain-MAE:227.508\n",
      "[30]\teval-rmse:322.623\ttrain-rmse:323.34\teval-MAE:206.786\ttrain-MAE:198.949\n",
      "[40]\teval-rmse:309.835\ttrain-rmse:300.468\teval-MAE:198.621\ttrain-MAE:180.689\n",
      "[50]\teval-rmse:302.614\ttrain-rmse:284.37\teval-MAE:194.372\ttrain-MAE:167.972\n",
      "[60]\teval-rmse:298.287\ttrain-rmse:272.518\teval-MAE:192.065\ttrain-MAE:158.72\n",
      "[70]\teval-rmse:295.573\ttrain-rmse:263.614\teval-MAE:190.857\ttrain-MAE:151.774\n",
      "[80]\teval-rmse:293.701\ttrain-rmse:256.259\teval-MAE:190.16\ttrain-MAE:146.174\n",
      "[90]\teval-rmse:292.582\ttrain-rmse:250.436\teval-MAE:189.857\ttrain-MAE:141.823\n",
      "[100]\teval-rmse:291.853\ttrain-rmse:245.673\teval-MAE:189.798\ttrain-MAE:138.34\n",
      "[110]\teval-rmse:291.241\ttrain-rmse:242.064\teval-MAE:189.73\ttrain-MAE:135.679\n",
      "[120]\teval-rmse:290.906\ttrain-rmse:238.918\teval-MAE:189.801\ttrain-MAE:133.406\n",
      "[130]\teval-rmse:290.752\ttrain-rmse:236.506\teval-MAE:189.983\ttrain-MAE:131.682\n",
      "[140]\teval-rmse:290.675\ttrain-rmse:234.34\teval-MAE:190.148\ttrain-MAE:130.145\n",
      "[149]\teval-rmse:290.614\ttrain-rmse:232.614\teval-MAE:190.295\ttrain-MAE:128.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "parc_data_hour_train_test[\"xgb_all\"]=np.nan    \n",
    "xgdtrain = xgb.DMatrix(parc_data_hour_train_train[list_col_model], parc_data_hour_train_train[col_target]) \n",
    "xgdtest = xgb.DMatrix(parc_data_hour_train_test[list_col_model], parc_data_hour_train_test[col_target])\n",
    "evallist  = [(xgdtest,'eval'), (xgdtrain,'train')]\n",
    "print(\"mae optimiser \")\n",
    "xgb_model = xgb.train(params = our_params ,dtrain = xgdtrain, evals=evallist, num_boost_round = 150,verbose_eval=10,obj=fair_obj,feval=mean_absolute_err)\n",
    "parc_data_hour_train_test[\"xgb_all\"] = xgb_model.predict(xgdtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182.94499119380373"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(parc_data_hour_train_test[col_target],(0.3*parc_data_hour_train_test[\"xgb_all\"]+1.7*parc_data_hour_train_test[\"xgb_site\"])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189500    23.0\n",
       "189508    24.0\n",
       "189519    25.0\n",
       "189530    26.0\n",
       "189541    27.0\n",
       "189552    28.0\n",
       "189563    29.0\n",
       "189574    30.0\n",
       "189585    31.0\n",
       "189596    32.0\n",
       "189607    33.0\n",
       "189618    34.0\n",
       "189629    35.0\n",
       "189640    36.0\n",
       "189651    37.0\n",
       "189662    38.0\n",
       "189673    39.0\n",
       "189684    40.0\n",
       "189695    41.0\n",
       "189706    42.0\n",
       "189717    43.0\n",
       "189728    44.0\n",
       "189739    45.0\n",
       "189750    46.0\n",
       "Name: fc_hor_10, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parc_data_hour_test.fc_hor_10.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5088: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# second validation\n",
    "res = parc_data_hour_test[[\"Date_hour_int\",\"Eolienne\"]]\n",
    "res[\"pred\"] =np.nan\n",
    "\n",
    "for eol_name in eolienne_list:\n",
    "    Eolienne_index = parc_data_hour_train[\"Eolienne\"]==eol_name\n",
    "    xgdmat = xgb.DMatrix(parc_data_hour_train[Eolienne_index][list_col_model], parc_data_hour_train[Eolienne_index][col_target])\n",
    "    xgb_model = xgb.train(params = our_params ,dtrain = xgdmat, num_boost_round = 250,verbose_eval=10,obj=fair_obj,feval=mean_absolute_err)\n",
    "    \n",
    "    Eolienne_index = parc_data_hour_test[\"Eolienne\"]==eol_name\n",
    "    res[\"pred\"][Eolienne_index]=xgb_model.predict(xgb.DMatrix(parc_data_hour_test[Eolienne_index][list_col_model]))\n",
    "save_adr = \"..//submission//sub_09_15_3.csv\"\n",
    "submission_generation(res,save_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\IA2069\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "res = parc_data_hour_test[[\"Date_hour_int\",\"Eolienne\"]]\n",
    "res[\"pred\"] =np.nan\n",
    "\n",
    "xgdmat = xgb.DMatrix(parc_data_hour_train[list_col_model], parc_data_hour_train[col_target])\n",
    "xgb_model = xgb.train(params = our_params ,dtrain = xgdmat, num_boost_round = 150,verbose_eval=10,obj=fair_obj,feval=mean_absolute_err)\n",
    "res[\"pred\"]=xgb_model.predict(xgb.DMatrix(parc_data_hour_test[list_col_model]))\n",
    "\n",
    "save_adr = \"..//submission//sub_09_15_all.csv\"\n",
    "submission_generation(res,save_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_1 = pd.read_csv(\"..//submission//sub_09_15_3.csv\",sep=\";\")\n",
    "submission_2 = pd.read_csv(\"..//submission//sub_09_15_all.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_1[\"pred\"] =0.85*submission_1[\"pred\"] + 0.15*submission_2[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_1.to_csv(\"..//submission//sub_09_15_combine.csv\",sep=';',header=True,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
